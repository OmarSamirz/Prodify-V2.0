# Model Performance Analysis Documentation

This document provides a comprehensive overview of the analysis graphs generated by the plotting functions in `analysis.py`. The analysis evaluates the ensemble model performance across multiple hierarchical levels: segment, family, and class.

## Overview

The analysis consists of several types of visualizations that examine different aspects of model performance:

1. **Confidence Level Distribution Analysis**
2. **Classification Results Analysis**
3. **Sublevel Classification Analysis**

---

## 1. Confidence Level Distribution Analysis

### Purpose
These graphs analyze how confidence levels are distributed across different hierarchy levels, helping to understand model certainty patterns.

### Generated Files
- `full_confidence_distribution.png` - Overall confidence distribution
- `correct_confidence_distribution.png` - Confidence distribution for correct predictions only
- `incorrect_confidence_distribution.png` - Confidence distribution for incorrect predictions only

### Graph Description
- **Type**: Stacked bar chart
- **X-axis**: Hierarchy levels (Segment, Family, Class)
- **Y-axis**: Percentage of predictions
- **Color Coding**:
  - ðŸ”´ Red (`#d73027`): Low confidence
  - ðŸŸ  Orange (`#fc8d59`): Medium confidence
  - ðŸŸ¢ Green (`#1a9850`): High confidence

### Interpretation
- **High green portions**: Model is confident in its predictions at the corresponding GPC level
- **High red portions**: Model uncertainty is high at the corresponding GPC level
- **Comparison between files**: 
  - If correct predictions show higher confidence than incorrect ones, the model's confidence correlates well with accuracy
  - If distributions are similar, confidence may not be a reliable indicator

---

## 2. Classification Results Analysis

### Purpose  
These graphs provide insights into model performance at each hierarchy level (Segment, Family, Class). Two complementary views are presented:  
- **Counts**: Absolute numbers of correct vs. incorrect predictions per label.  
- **Percentages**: Accuracy normalized by label frequency, highlighting performance relative to class imbalance.  

### Generated Files  
- **Counts**  
  - `model_performance_segment_absolute_value.png`  
  - `model_performance_family_absolute_value.png`  
  - `model_performance_class_absolute_value.png`  
- **Percentages**  
  - `model_performance_segment_percentage.png`  
  - `model_performance_family_percentage.png`  
  - `model_performance_class_percentage.png`  

### Graph Description  
- **Type**: Two-way bar chart  
- **X-axis**: Labels within the hierarchy level (sorted by total count, descending)  
- **Y-axis**:  
  - Counts view â†’ Number of predictions (symmetric log scale)  
  - Percentages view â†’ Accuracy percentage (0â€“100%)  
- **Layout**:  
  - ðŸŸ¢ Green bars above x-axis: Correct predictions/percentages  
  - ðŸ”´ Red bars below x-axis: Incorrect predictions/percentages  
- **Statistics Box**: Displays top 5 and bottom 5 labels  

### Interpretation  
- **Counts view**  
  - Taller green bars â†’ Labels with high correct prediction volume  
  - Taller red bars â†’ Labels the model struggles with most  
  - Imbalanced bars â†’ Possible class imbalance issues  
  - Log scale â†’ Enables visibility across both high- and low-frequency labels  
- **Percentages view**  
  - 100% green, 0% red â†’ Perfect accuracy for that label  
  - Balanced bars (~50/50) â†’ Model performs at chance level  
  - High red percentage â†’ Consistent misclassification for that label  
- **Cross-comparison**  
  - Counts highlight impact of errors on frequent classes  
  - Percentages reveal whether poor performance is due to label difficulty or small sample size  

---

## 3. Sublevel Classification Analysis

### Purpose
These graphs provide detailed analysis by breaking down performance **within specific sublevels of each upper-level category** (e.g., Families inside a Segment, or Classes inside a Family). This allows identification of performance patterns nested within parent categories.

### Generated Files
- `model_performance_by_each_segment/`  
  Contains one image per Segment 
  - `[family_name]_[index].png`

- `model_performance_by_each_family/`  
  Contains one image per Family   
  - `[class_name]_[index].png`

### Graph Description
- **Type**: Two-way bar chart (correct above x-axis, incorrect below)  
- **X-axis**: Sublevel labels within the given upper level (e.g., Families inside a Segment)  
- **Y-axis**: Number of predictions (symmetric log scale, `symlog`)  
- **Color Coding**:  
  - ðŸŸ¢ Green: Correct predictions  
  - ðŸ”´ Red: Incorrect predictions  
- **Statistics Box**: Shows parent-level totals, including total predictions, correct/incorrect counts, and accuracy percentage.

### Interpretation
- **Parent-level breakdown**: For each Segment, see how its Families performed individually; for each Family, see how its Classes performed.  
- **Performance hotspots**: Identify which sublevels are most problematic inside their parent categories.  
- **Comparative analysis**: Compare sublevel behavior across different parent groups.  
- **Targeted improvement**: Pinpoint where the model struggles most, enabling focused retraining or data augmentation.  

---

## Usage Guidelines

### Interpreting Model Performance
1. **Start with confidence distributions** to understand model certainty patterns
2. **Examine absolute value based graphs** to identify high-impact labels and class imbalance
3. **Review percentage graphs** to assess true performance independent of frequency
4. **Dive into sublevel analysis** for detailed performance debugging

### Identifying Issues
- **Low confidence + poor performance**: Model genuinely struggles with these labels
- **High confidence + poor performance**: Model is overconfident; may need calibration
- **Good overall performance but poor sublevel performance**: Indicates specific subcategory issues
- **Imbalanced counts**: May indicate need for data augmentation or weighted training

---

## File Organization

```
## File Organization

analysis/
â”œâ”€â”€ analysis.py
â”œâ”€â”€ analysis.md
â”œâ”€â”€ full_confidence_distribution.png
â”œâ”€â”€ correct_confidence_distribution.png
â”œâ”€â”€ incorrect_confidence_distribution.png
â”œâ”€â”€ model_performance_segment_absolute_value.png
â”œâ”€â”€ model_performance_family_absolute_value.png
â”œâ”€â”€ model_performance_class_absolute_value.png
â”œâ”€â”€ model_performance_segment_percentage.png
â”œâ”€â”€ model_performance_family_percentage.png
â”œâ”€â”€ model_performance_class_percentage.png
â”œâ”€â”€ model_performance_by_each_segment/
â”‚   â”œâ”€â”€ [segment_name]_by_family.png
â”‚   â””â”€â”€ ...
â””â”€â”€ model_performance_by_each_family/
    â”œâ”€â”€ [family_name]_by_class.png
    â””â”€â”€ ...
```

## Technical Notes

- **Log Scale**: Used for absolute value graphs to handle wide range of label frequencies
- **Symmetric Log Scale**: Used for two-way bar charts to handle both positive and negative values
- **Color Consistency**: Green always represents correct/positive, red represents incorrect/negative
- **Sorting**: All graphs sort labels by total frequency (descending) rather than alphabetically

---

*Generated by the analysis pipeline - refer to `analysis.py` for implementation details.*