{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def83095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HANConv, GATConv\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import load_embedding_model\n",
    "from constants import FULL_DATASET_PATH, E5_LARGE_INSTRUCT_CONFIG_PATH, RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c494ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605f15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FULL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89bb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e433f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_seg = LabelEncoder()\n",
    "le_fam = LabelEncoder()\n",
    "le_cls = LabelEncoder()\n",
    "\n",
    "df[\"segment_encode\"] = le_seg.fit_transform(df[\"segment\"])\n",
    "df[\"family_encode\"]  = le_fam.fit_transform(df[\"family\"])\n",
    "df[\"class_encode\"]   = le_cls.fit_transform(df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = load_embedding_model(E5_LARGE_INSTRUCT_CONFIG_PATH)\n",
    "\n",
    "product_embeds = embed_model.get_embeddings(df[\"product_name\"].tolist())\n",
    "product_embeds = torch.tensor(product_embeds, dtype=torch.float32)  # shape [N_products, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46cad0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_y = torch.tensor(df[\"segment_encode\"].values, dtype=torch.long)  # shape [N_products]\n",
    "family_y = torch.tensor(df[\"family_encode\"].values, dtype=torch.long)  # shape [N_products]\n",
    "class_y = torch.tensor(df[\"class_encode\"].values, dtype=torch.long)  # shape [N_products]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b0056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(len(df)))\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "test_mask  = torch.zeros(len(df), dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74421f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products = len(df)\n",
    "num_segments = df[\"segment_encode\"].nunique()\n",
    "num_families = df[\"family_encode\"].nunique()\n",
    "num_classes  = df[\"class_encode\"].nunique()\n",
    "\n",
    "# --- Product to Segment edges ---\n",
    "prod_to_seg_src = torch.arange(num_products, dtype=torch.long)\n",
    "prod_to_seg_dst = torch.tensor(df[\"segment_encode\"].values, dtype=torch.long)\n",
    "prod_to_seg_edge_index = torch.stack([prod_to_seg_src, prod_to_seg_dst], dim=0)\n",
    "\n",
    "# --- Segment to Family edges ---\n",
    "seg_to_fam_src = torch.tensor(df[\"segment_encode\"].values, dtype=torch.long)\n",
    "seg_to_fam_dst = torch.tensor(df[\"family_encode\"].values, dtype=torch.long)\n",
    "seg_to_fam_edge_index = torch.stack([seg_to_fam_src, seg_to_fam_dst], dim=0)\n",
    "\n",
    "# --- Family to Class edges ---\n",
    "fam_to_cls_src = torch.tensor(df[\"family_encode\"].values, dtype=torch.long)\n",
    "fam_to_cls_dst = torch.tensor(df[\"class_encode\"].values, dtype=torch.long)\n",
    "fam_to_cls_edge_index = torch.stack([fam_to_cls_src, fam_to_cls_dst], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26aac3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Product nodes\n",
    "data[\"product\"].x = product_embeds\n",
    "# data[\"product\"].segment = segment_y\n",
    "# data[\"product\"].family = family_y\n",
    "# data[\"product\"]._class = class_y\n",
    "data[\"product\"].train_mask = train_mask\n",
    "data[\"product\"].test_mask = test_mask\n",
    "data[\"product\"].y = class_y\n",
    "\n",
    "# Segment / Family / Class nodes don’t have features (yet)\n",
    "# They’ll get embeddings via the NodeFeatureEncoder\n",
    "data[\"segment\"].num_nodes = num_segments\n",
    "data[\"family\"].num_nodes  = num_families\n",
    "data[\"class\"].num_nodes   = num_classes\n",
    "\n",
    "# Edges\n",
    "data[\"product\", \"to\", \"segment\"].edge_index = prod_to_seg_edge_index\n",
    "data[\"segment\", \"to\", \"family\"].edge_index  = seg_to_fam_edge_index\n",
    "data[\"family\", \"to\", \"class\"].edge_index    = fam_to_cls_edge_index\n",
    "\n",
    "# Reverse edges\n",
    "data[\"segment\", \"rev_to\", \"product\"].edge_index = prod_to_seg_edge_index.flip(0)\n",
    "data[\"family\", \"rev_to\", \"segment\"].edge_index  = seg_to_fam_edge_index.flip(0)\n",
    "data[\"class\", \"rev_to\", \"family\"].edge_index    = fam_to_cls_edge_index.flip(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4030f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "from typing import Optional, Dict\n",
    "\n",
    "# -------------------------\n",
    "# NodeFeatureEncoder (same as before)\n",
    "# -------------------------\n",
    "class NodeFeatureEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        prod_in_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_families: Optional[int] = None,\n",
    "        num_segments: Optional[int] = None,\n",
    "        num_classes: Optional[int] = None,\n",
    "        pretrained_category_embeddings: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.product_proj = nn.Linear(prod_in_dim, hidden_dim)\n",
    "        self.pretrained = pretrained_category_embeddings or {}\n",
    "\n",
    "        if 'segment' in self.pretrained:\n",
    "            self.register_buffer('segment_pre', self.pretrained['segment'])\n",
    "            self.segment_embedding = None\n",
    "            seg_in_dim = self.pretrained['segment'].shape[1]\n",
    "        else:\n",
    "            assert num_segments is not None, \"num_segments required if no pretrained segment embeddings\"\n",
    "            seg_in_dim = hidden_dim\n",
    "            self.segment_embedding = nn.Embedding(num_segments, seg_in_dim)\n",
    "\n",
    "        if 'family' in self.pretrained:\n",
    "            self.register_buffer('family_pre', self.pretrained['family'])\n",
    "            self.family_embedding = None\n",
    "            fam_in_dim = self.pretrained['family'].shape[1]\n",
    "        else:\n",
    "            assert num_families is not None, \"num_families required if no pretrained family embeddings\"\n",
    "            fam_in_dim = hidden_dim\n",
    "            self.family_embedding = nn.Embedding(num_families, fam_in_dim)\n",
    "\n",
    "        if 'class' in self.pretrained:\n",
    "            self.register_buffer('class_pre', self.pretrained['class'])\n",
    "            self.class_embedding = None\n",
    "            class_in_dim = self.pretrained['class'].shape[1]\n",
    "        else:\n",
    "            assert num_classes is not None, \"num_classes required if no pretrained class embeddings\"\n",
    "            class_in_dim = hidden_dim\n",
    "            self.class_embedding = nn.Embedding(num_classes, class_in_dim)\n",
    "\n",
    "        # project category dims -> hidden_dim\n",
    "        self.segment_proj = nn.Linear(seg_in_dim, hidden_dim)\n",
    "        self.family_proj  = nn.Linear(fam_in_dim, hidden_dim)\n",
    "        self.class_proj   = nn.Linear(class_in_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, product_x, segment_idx_or_none=None, family_idx_or_none=None, class_idx_or_none=None):\n",
    "        out = {}\n",
    "        out['product'] = self.product_proj(product_x)\n",
    "\n",
    "        if hasattr(self, 'segment_pre') and self.segment_pre is not None:\n",
    "            seg_feats = self.segment_pre\n",
    "        else:\n",
    "            seg_feats = self.segment_embedding(segment_idx_or_none)\n",
    "        out['segment'] = self.segment_proj(seg_feats)\n",
    "\n",
    "        if hasattr(self, 'family_pre') and self.family_pre is not None:\n",
    "            fam_feats = self.family_pre\n",
    "        else:\n",
    "            fam_feats = self.family_embedding(family_idx_or_none)\n",
    "        out['family'] = self.family_proj(fam_feats)\n",
    "\n",
    "        if hasattr(self, 'class_pre') and self.class_pre is not None:\n",
    "            class_feats = self.class_pre\n",
    "        else:\n",
    "            class_feats = self.class_embedding(class_idx_or_none)\n",
    "        out['class'] = self.class_proj(class_feats)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Hetero GNN with updated relations\n",
    "# -------------------------\n",
    "class HeteroSAGENet(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, out_classes: int, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                # forward relations (updated)\n",
    "                ('product', 'to', 'segment'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('segment', 'to', 'family'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('family', 'to', 'class'): SAGEConv((-1, -1), hidden_dim),\n",
    "                # reverse relations\n",
    "                ('segment', 'rev_to', 'product'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('family', 'rev_to', 'segment'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('class', 'rev_to', 'family'): SAGEConv((-1, -1), hidden_dim),\n",
    "            }, aggr='mean')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.bn_product = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_segment = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_family  = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_class   = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = x_dict\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index_dict)\n",
    "            x['product'] = F.relu(self.bn_product(x['product']))\n",
    "            x['segment'] = F.relu(self.bn_segment(x['segment']))\n",
    "            x['family']  = F.relu(self.bn_family(x['family']))\n",
    "            x['class']   = F.relu(self.bn_class(x['class']))\n",
    "\n",
    "            x['product'] = F.dropout(x['product'], p=self.dropout, training=self.training)\n",
    "            x['segment'] = F.dropout(x['segment'], p=self.dropout, training=self.training)\n",
    "            x['family']  = F.dropout(x['family'], p=self.dropout, training=self.training)\n",
    "            x['class']   = F.dropout(x['class'], p=self.dropout, training=self.training)\n",
    "\n",
    "        logits = self.classifier(x['product'])\n",
    "        return logits, x\n",
    "    \n",
    "class HeteroAttnNet(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, out_classes: int, num_layers: int = 2, dropout: float = 0.1, heads: int = 2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                # forward relations\n",
    "                ('product', 'to', 'segment'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "                ('segment', 'to', 'family'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "                ('family', 'to', 'class'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "                # reverse relations\n",
    "                ('segment', 'rev_to', 'product'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "                ('family', 'rev_to', 'segment'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "                ('class', 'rev_to', 'family'): GATConv(\n",
    "                    (-1, -1), hidden_dim, heads=heads, concat=False, add_self_loops=False\n",
    "                ),\n",
    "            }, aggr='mean')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # batchnorms\n",
    "        self.bn_product = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_segment = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_family  = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn_class   = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = x_dict\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index_dict)\n",
    "\n",
    "            x['product'] = F.relu(self.bn_product(x['product']))\n",
    "            x['segment'] = F.relu(self.bn_segment(x['segment']))\n",
    "            x['family']  = F.relu(self.bn_family(x['family']))\n",
    "            x['class']   = F.relu(self.bn_class(x['class']))\n",
    "\n",
    "            x['product'] = F.dropout(x['product'], p=self.dropout, training=self.training)\n",
    "            x['segment'] = F.dropout(x['segment'], p=self.dropout, training=self.training)\n",
    "            x['family']  = F.dropout(x['family'], p=self.dropout, training=self.training)\n",
    "            x['class']   = F.dropout(x['class'], p=self.dropout, training=self.training)\n",
    "\n",
    "        logits = self.classifier(x['product'])\n",
    "        return logits, x\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Training wrapper (updated edge names/order)\n",
    "# -------------------------\n",
    "def train_model(\n",
    "    product_embeddings,                # tensor [N_p, 1024]\n",
    "    product_to_segment_edge_index,     # long tensor [2, E_ps]\n",
    "    segment_to_family_edge_index,      # long tensor [2, E_sf]\n",
    "    family_to_class_edge_index,        # long tensor [2, E_fc]\n",
    "    product_y,                         # long tensor [N_p]\n",
    "    product_train_mask,                # bool tensor [N_p]\n",
    "    product_test_mask,                 # bool tensor [N_p]\n",
    "    num_families=None,\n",
    "    num_segments=None,\n",
    "    num_classes=None,\n",
    "    pretrained_category_embeddings: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    heads=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    "):\n",
    "    data = HeteroData()\n",
    "    data['product'].x = product_embeddings\n",
    "    data['product'].y = product_y\n",
    "    data['product'].train_mask = product_train_mask\n",
    "    data['product'].test_mask = product_test_mask\n",
    "\n",
    "    # Updated edges\n",
    "    data['product', 'to', 'segment'].edge_index = product_to_segment_edge_index\n",
    "    data['segment', 'to', 'family'].edge_index = segment_to_family_edge_index\n",
    "    data['family', 'to', 'class'].edge_index = family_to_class_edge_index\n",
    "\n",
    "    # reverse edges (flip rows)\n",
    "    data['segment', 'rev_to', 'product'].edge_index = product_to_segment_edge_index.flip(0)\n",
    "    data['family', 'rev_to', 'segment'].edge_index = segment_to_family_edge_index.flip(0)\n",
    "    data['class', 'rev_to', 'family'].edge_index = family_to_class_edge_index.flip(0)\n",
    "\n",
    "    encoder = NodeFeatureEncoder(\n",
    "        prod_in_dim=product_embeddings.size(1),\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_families=num_families,\n",
    "        num_segments=num_segments,\n",
    "        num_classes=num_classes,\n",
    "        pretrained_category_embeddings=pretrained_category_embeddings\n",
    "    ).to(device)\n",
    "\n",
    "    model = None\n",
    "    if heads is not None:\n",
    "        model = HeteroAttnNet(hidden_dim=hidden_dim, out_classes=num_classes, num_layers=num_layers, heads=heads).to(device)\n",
    "    else: \n",
    "        model = HeteroSAGENet(hidden_dim=hidden_dim, out_classes=num_classes, num_layers=num_layers).to(device)\n",
    "    \n",
    "    params = list(encoder.parameters()) + list(model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # category indices for embedding path (if needed)\n",
    "    segment_idx = torch.arange(num_segments, dtype=torch.long, device=device) if (pretrained_category_embeddings is None or 'segment' not in (pretrained_category_embeddings or {})) else None\n",
    "    family_idx  = torch.arange(num_families, dtype=torch.long, device=device)  if (pretrained_category_embeddings is None or 'family' not in (pretrained_category_embeddings or {})) else None\n",
    "    class_idx   = torch.arange(num_classes, dtype=torch.long, device=device)   if (pretrained_category_embeddings is None or 'class' not in (pretrained_category_embeddings or {})) else None\n",
    "\n",
    "    data = data.to(device)\n",
    "    product_embeddings = product_embeddings.to(device)\n",
    "    product_y = product_y.to(device)\n",
    "    product_train_mask = product_train_mask.to(device)\n",
    "    product_test_mask = product_test_mask.to(device)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        encoder.train(); model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_dict = encoder(product_embeddings, segment_idx, family_idx, class_idx)\n",
    "        logits, _ = model(x_dict, data.edge_index_dict)\n",
    "\n",
    "        loss = F.cross_entropy(logits[product_train_mask], product_y[product_train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and epoch % max(1, epochs//10) == 0:\n",
    "            encoder.eval(); model.eval()\n",
    "            with torch.inference_mode():\n",
    "                x_eval = encoder(product_embeddings, segment_idx, family_idx, class_idx)\n",
    "                logits_eval, _ = model(x_eval, data.edge_index_dict)\n",
    "                pred = logits_eval.argmax(dim=-1)\n",
    "                train_acc = (pred[product_train_mask] == product_y[product_train_mask]).sum().item() / max(1, int(product_train_mask.sum().item()))\n",
    "                test_acc = (pred[product_test_mask] == product_y[product_test_mask]).sum().item() / max(1, int(product_test_mask.sum().item()))\n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                best_state = {'encoder': encoder.state_dict(), 'model': model.state_dict(), 'epoch': epoch, 'test_acc': test_acc}\n",
    "            print(f\"\\nEpoch {epoch:03d} | Loss: {loss.item():.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nTraining finished. Best test acc:\", best_test_acc)\n",
    "    return encoder, model, best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b07517ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, model, best_state = train_model(\n",
    "    product_embeddings=data[\"product\"].x,                  # [N_products, 1024]\n",
    "    product_to_segment_edge_index=data[\"product\", \"to\", \"segment\"].edge_index,\n",
    "    segment_to_family_edge_index=data[\"segment\", \"to\", \"family\"].edge_index,\n",
    "    family_to_class_edge_index=data[\"family\", \"to\", \"class\"].edge_index,\n",
    "    product_y=data[\"product\"].y,                           # class labels\n",
    "    product_train_mask=data[\"product\"].train_mask,         # boolean mask\n",
    "    product_test_mask=data[\"product\"].test_mask,           # boolean mask\n",
    "    num_segments=data[\"segment\"].num_nodes,\n",
    "    num_families=data[\"family\"].num_nodes,\n",
    "    num_classes=data[\"class\"].num_nodes,\n",
    "    hidden_dim=128,       # you can tune\n",
    "    num_layers=3,         # number of GNN layers\n",
    "    # heads=2,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    epochs=200,            # train longer for better results\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca74824",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba67010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodify-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
